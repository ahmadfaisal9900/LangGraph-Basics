{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2b90708",
   "metadata": {},
   "source": [
    "## Graph API Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ceb8844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated \n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages # ----> reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63863b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    \n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4357c8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAcdexP7G-_JzK8GDjh46BRSf7IJbFV2C0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adf0218c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760101015.725252   59700 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(\"google_genai:gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f04b7ff",
   "metadata": {},
   "source": [
    "here we're adding our first node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2550d083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7bbcfae01730>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chatbot(state:State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e1481d",
   "metadata": {},
   "source": [
    "adding the entry point (edge) from Start -> chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2efeaee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7bbcfae01730>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b1a11e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7bbcfae01730>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(\"chatbot\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5783c3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dd532f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+  \n",
      "| __start__ |  \n",
      "+-----------+  \n",
      "      *        \n",
      "      *        \n",
      "      *        \n",
      " +---------+   \n",
      " | chatbot |   \n",
      " +---------+   \n",
      "      *        \n",
      "      *        \n",
      "      *        \n",
      " +---------+   \n",
      " | __end__ |   \n",
      " +---------+   \n"
     ]
    }
   ],
   "source": [
    "graph.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5c27935",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmad-faisal/miniconda3/envs/lang/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:2007: UserWarning: HumanMessage with empty content was removed to prevent API error\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What do you know about LangGraph?\n",
      "Assistant: LangGraph is a Python library built on top of LangChain that allows you to create **stateful, multi-actor applications** using a graph-based architecture. Think of it as a framework for building more complex and robust conversational AI agents that can reason, plan, and reflect over time.\n",
      "\n",
      "Here's a breakdown of what I know about LangGraph:\n",
      "\n",
      "**Key Concepts and Features:**\n",
      "\n",
      "*   **Graph-Based Architecture:** The core idea is to represent the application's logic as a directed graph. Nodes in the graph represent different \"actors\" or states in the application, and edges define the flow of information between them. This makes it easier to visualize, understand, and manage complex agent workflows.\n",
      "\n",
      "*   **Nodes (Actors):** Nodes in the graph are the fundamental building blocks. They can represent:\n",
      "    *   **LLMs (Language Model Calls):**  Calling a large language model (like GPT-4) to generate text, translate, summarize, etc.\n",
      "    *   **Tools:** Using external tools like search engines, calculators, databases, etc.\n",
      "    *   **Functions:** Executing custom Python functions.\n",
      "    *   **Conditional Logic:**  Making decisions based on the current state of the application.\n",
      "    *   **State Updates:** Modifying the application's state.\n",
      "\n",
      "*   **Edges:** Edges define how the application flows from one node to another. They can be:\n",
      "    *   **Conditional Edges:**  The next node is determined by a condition (e.g., if the user asks a specific question, go to a specific node).\n",
      "    *   **Unconditional Edges:**  The application always flows to the next node.\n",
      "\n",
      "*   **State:**  LangGraph maintains a state object that represents the current state of the application.  This state is passed between nodes and can be updated by them.  This allows the agent to \"remember\" past interactions and use that information to make better decisions.\n",
      "\n",
      "*   **Cycles (Loops):**  One of the powerful features of LangGraph is the ability to create cycles in the graph. This allows the agent to loop back to previous nodes and refine its reasoning or try different approaches. This is crucial for tasks that require multiple iterations or reflection.\n",
      "\n",
      "*   **Concurrency:** LangGraph can execute nodes concurrently, which can significantly improve performance, especially when dealing with multiple LLM calls or tool use.\n",
      "\n",
      "*   **Observability and Debugging:**  LangGraph provides tools for visualizing the graph, inspecting the state, and debugging the application.\n",
      "\n",
      "**Benefits of Using LangGraph:**\n",
      "\n",
      "*   **Improved Agent Reasoning and Planning:**  The graph-based architecture makes it easier to design agents that can reason about complex tasks and plan their actions accordingly.\n",
      "\n",
      "*   **Increased Robustness:**  By using cycles and conditional logic, you can create agents that are more robust to errors and unexpected user input.\n",
      "\n",
      "*   **Better Observability and Debugging:**  The visualization and debugging tools make it easier to understand what the agent is doing and identify potential problems.\n",
      "\n",
      "*   **Modularity and Reusability:**  Nodes can be reused in different parts of the graph, making it easier to build and maintain complex applications.\n",
      "\n",
      "*   **State Management:** Built-in state management makes it easier to track the progress of the conversation and use that information to guide the agent's behavior.\n",
      "\n",
      "**Use Cases:**\n",
      "\n",
      "*   **Chatbots with Complex Dialog Flows:**  Create chatbots that can handle complex conversations with multiple branches and conditions.\n",
      "\n",
      "*   **Autonomous Agents:**  Build agents that can autonomously plan and execute tasks, such as scheduling meetings, booking flights, or writing code.\n",
      "\n",
      "*   **RAG (Retrieval-Augmented Generation) Systems:**  Improve the accuracy and relevance of RAG systems by using LangGraph to manage the retrieval and generation process.\n",
      "\n",
      "*   **Decision-Making Agents:** Create agents that can make complex decisions based on a variety of factors.\n",
      "\n",
      "**How LangGraph Relates to LangChain:**\n",
      "\n",
      "LangGraph is built *on top* of LangChain. It leverages LangChain's components (LLMs, tools, chains, etc.) and provides a framework for orchestrating them in a more structured and stateful way. You'll often use LangChain components within the nodes of your LangGraph.\n",
      "\n",
      "**Example (Simplified):**\n",
      "\n",
      "Imagine a simple chatbot that can answer questions about animals.  A LangGraph might have these nodes:\n",
      "\n",
      "1.  **Get User Input:**  Gets the user's question.\n",
      "2.  **Check for Greeting:**  Checks if the user is saying hello. If so, goes to a \"Greeting\" node.\n",
      "3.  **Search for Animal Information:**  Uses a search tool to find information about the animal.\n",
      "4.  **Generate Response:**  Uses an LLM to generate a response based on the search results.\n",
      "5.  **Greeting:**  Responds with a greeting.\n",
      "6.  **End:**  Ends the conversation.\n",
      "\n",
      "The edges would define the flow between these nodes. For example, after \"Get User Input,\" the edge would go to \"Check for Greeting.\"  If the user is greeting the bot, the graph branches to the \"Greeting\" node, then to the \"End\" node.  Otherwise, it goes to \"Search for Animal Information,\" and so on.\n",
      "\n",
      "**In summary, LangGraph provides a powerful and flexible way to build complex, stateful, and robust conversational AI agents by leveraging a graph-based architecture. It builds on the foundation of LangChain and extends its capabilities to handle more sophisticated use cases.**\n",
      "\n",
      "To learn more, I recommend checking out the official LangChain documentation and tutorials on LangGraph. They provide detailed explanations and examples of how to use the library.\n"
     ]
    }
   ],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf732b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
