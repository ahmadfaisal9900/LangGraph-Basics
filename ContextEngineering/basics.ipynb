{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d5c602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1760440988.003337   37472 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Annotated, List, Literal\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.tools import tool\n",
    "from langchain_tavily import TavilySearch\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, END, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "from typing import TypedDict, Annotated, List, Literal, Dict, Any\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import random\n",
    "from datetime import datetime\n",
    "from langgraph.graph.message import add_messages # ----> reducer\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = google_api_key\n",
    "os.environ[\"TAVILY_API_KEY\"] = tavily_api_key \n",
    "\n",
    "llm = init_chat_model(\"google_genai:gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4971b80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    \n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "def chatbot(state:State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e35774f",
   "metadata": {},
   "source": [
    "### Atomic Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0675fb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do programmers prefer dark mode?\n",
      "\n",
      "Because light attracts bugs!\n"
     ]
    }
   ],
   "source": [
    "def generate(prompt: str) -> str:\n",
    "    response = graph.invoke({\n",
    "        \"messages\": [HumanMessage(content=prompt)]\n",
    "    })\n",
    "    return response[\"messages\"][-1].content\n",
    "response = generate(\"Write a joke about programmers.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b53595",
   "metadata": {},
   "source": [
    "### Prompt with a constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "315e2569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the programmer's doctor recommend regular stretching?\n",
      "\n",
      "Because after debugging for 72 hours straight, they found out their legs had become a permanent part of their chair. They were officially \"integrated.\"\n"
     ]
    }
   ],
   "source": [
    "response = generate(\"Write a joke about programmers that has to do with them not leaving their chair for a long time.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57306028",
   "metadata": {},
   "source": [
    "#### We can write few shot or whatever too, or assign a role (usually the system prompt things)(im too lazy to do all of that)\n",
    "\n",
    "#### Let's try a system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84a54b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright, buckle up, buttercups, because I've got a tale for you that's funnier than a rubber chicken in a library!\n",
      "\n",
      "So, picture this: There's this programmer, right? A real coding cowboy, name of \"Binary\" Bob. Now, Bob, he loved coding more than squirrels love nuts. He'd sit in his chair, surrounded by empty energy drink cans and enough snack wrappers to build a small fort, and just *code*. Days turned into nights, nights turned into... well, more nights. His apartment slowly started to resemble a digital cave, and his chair? Oh, that chair became an extension of his very being.\n",
      "\n",
      "One day, Bob's mom calls, bless her heart. She's worried sick, hasn't seen him in weeks. So, she drives over, knocks on the door, and after a bit of yelling, Bob finally grunts and shuffles to the door. Mom bursts in, takes one look at the scene, and gasps, \"Binary Bob! You haven't left this chair in days, have you?!\"\n",
      "\n",
      "Bob, without missing a beat, swivels around, points at the chair, and says:\n",
      "\n",
      "**\"Of course I have! I had to go to the bathroom!\"**\n",
      "\n",
      "Now, here's the kicker:\n",
      "\n",
      "**He said, while still sitting in the chair.**\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\" \n",
    "        You are a comedian that likes to tell stories before delivering a punchline. You are always funny. \n",
    "        Jokes contain 3 sections:\n",
    "        1. A setup\n",
    "        2. A punchline\n",
    "        3. A contradiction\n",
    "        Always maintain a jovial tone.\n",
    "\"\"\"\n",
    "\n",
    "def generate_with_system(prompt: str) -> str:\n",
    "    response = graph.invoke({\n",
    "        \"messages\": [\n",
    "            SystemMessage(content=system_prompt),\n",
    "            HumanMessage(content=prompt)\n",
    "        ]\n",
    "    })\n",
    "    return response[\"messages\"][-1].content\n",
    "response = generate_with_system(\"Write a joke about programmers that has to do with them not leaving their chair for a long time.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2343c6e",
   "metadata": {},
   "source": [
    "### Sometimes it might not follow this format,,, what then,,,?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93a2de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "lm = dspy.LM(\"gemini/gemini-2.0-flash\", api_key=google_api_key)\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3427100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd647d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078e8fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
